Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
1000,2.1714985,30.28125,2.0085926,-3.7146029760760646,-3.7146029760760646,1.0
2000,2.1705503,41.083333333333336,2.5725756,-3.4524351259072623,-3.4524351259072623,1.0
3000,2.17347,37.0,2.2265854,-3.5080721240777235,-3.5080721240777235,1.0
4000,2.1673396,30.606060606060606,2.1766973,-3.5735305291600525,-3.5735305291600525,1.0
5000,2.171849,31.666666666666668,2.0495088,-3.569445694646528,-3.569445694646528,1.0
6000,2.1701212,32.89655172413793,2.311578,-3.7109574094928544,-3.7109574094928544,1.0
7000,2.173219,34.6551724137931,2.0526562,-3.7250116746872663,-3.7250116746872663,1.0
8000,2.1751935,42.91304347826087,2.2824082,-3.8454810108827506,-3.8454810108827506,1.0
